{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d391b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f5ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [(0, 1), (1, 5), (5, 6), (5, 4), (1, 2), \n",
    "         (1, 3), (9, 10), (2, 4), (0, 6), (6, 7),\n",
    "         (8, 9), (7, 8), (1, 7), (3, 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e27c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = 10\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw_networkx_nodes(G, pos)\n",
    "nx.draw_networkx_edges(G, pos)\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d2876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATRIX_SIZE = 11\n",
    "M = np.matrix(np.ones(shape =(MATRIX_SIZE, MATRIX_SIZE)))\n",
    "M *= -1\n",
    "  \n",
    "for point in edges:\n",
    "    print(point)\n",
    "    if point[1] == goal:\n",
    "        M[point] = 100\n",
    "    else:\n",
    "        M[point] = 0\n",
    "  \n",
    "    if point[0] == goal:\n",
    "        M[point[::-1]] = 100\n",
    "    else:\n",
    "        M[point[::-1]]= 0\n",
    "        # reverse of point  \n",
    "M[goal, goal]= 100\n",
    "print(M)\n",
    "# add goal point round trip\n",
    "Q = np.matrix(np.zeros([MATRIX_SIZE, MATRIX_SIZE]))\n",
    " \n",
    "gamma = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09ecdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning parameter\n",
    "initial_state = 1\n",
    "  \n",
    "# Determines the available actions for a given state\n",
    "def available_actions(state):\n",
    "    current_state_row = M[state, ]\n",
    "    available_action = np.where(current_state_row >= 0)[1]\n",
    "    return available_action\n",
    "  \n",
    "available_action = available_actions(initial_state)\n",
    "  \n",
    "# Chooses one of the available actions at random\n",
    "def sample_next_action(available_actions_range):\n",
    "    next_action = int(np.random.choice(available_action, 1))\n",
    "    return next_action \n",
    "  \n",
    "action = sample_next_action(available_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c5baf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(current_state, action, gamma):\n",
    "  \n",
    "  max_index = np.where(Q[action, ] == np.max(Q[action, ]))[1]\n",
    "if max_index.shape[0] > 1:\n",
    "    max_index = int(np.random.choice(max_index, size = 1))\n",
    "else:\n",
    "    max_index = int(max_index)\n",
    "    max_value = Q[action, max_index]\n",
    "    Q[current_state, action] = M[current_state, action] + gamma * max_value\n",
    "if (np.max(Q) > 0):\n",
    "    return(np.sum(Q / np.max(Q)*100))\n",
    "else:\n",
    "    return (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa4d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates the Q-Matrix according to the path chosen\n",
    "  \n",
    "update(initial_state, action, gamma)\n",
    "scores = []\n",
    "for i in range(1000):\n",
    "    current_state = np.random.randint(0, int(Q.shape[0]))\n",
    "    available_action = available_actions(current_state)\n",
    "    action = sample_next_action(available_action)\n",
    "    score = update(current_state, action, gamma)\n",
    "    scores.append(score)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Trained Q matrix:\")\n",
    "# print(Q / np.max(Q)*100)\n",
    "# You can uncomment the above two lines to view the trained Q matrix\n",
    "  \n",
    "# Testing\n",
    "current_state = 0\n",
    "steps = [current_state]\n",
    "  \n",
    "while current_state != 10:\n",
    "    next_step_index = np.where(Q[current_state, ] == np.max(Q[current_state, ]))[1]\n",
    "    if next_step_index.shape[0] > 1:\n",
    "        next_step_index = int(np.random.choice(next_step_index, size = 1))\n",
    "    else:\n",
    "        \n",
    "            next_step_index = int(next_step_index)\n",
    "            steps.append(next_step_index)\n",
    "            current_state = next_step_index  \n",
    "print(\"Most efficient path:\")\n",
    "print(steps)\n",
    "  \n",
    "pl.plot(scores)\n",
    "pl.xlabel('No of iterations')\n",
    "pl.ylabel('Reward gained')\n",
    "pl.show()\n",
    "# Defining the locations of the police and the drug traces\n",
    "police = [2, 4, 5]\n",
    "drug_traces = [3, 8, 9]\n",
    "  \n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)\n",
    "mapping = {0:'0 - Detective', 1:'1', 2:'2 - Police', 3:'3 - Drug traces',\n",
    "           4:'4 - Police', 5:'5 - Police', 6:'6', 7:'7', 8:'Drug traces',\n",
    "           9:'9 - Drug traces', 10:'10 - Drug racket location'}\n",
    "  \n",
    "H = nx.relabel_nodes(G, mapping)\n",
    "pos = nx.spring_layout(H)\n",
    "nx.draw_networkx_nodes(H, pos, node_size =[200, 200, 200, 200, 200, 200, 200, 200])\n",
    "nx.draw_networkx_edges(H, pos)\n",
    "nx.draw_networkx_labels(H, pos)\n",
    "pl.show() \n",
    "Q = np.matrix(np.zeros([MATRIX_SIZE, MATRIX_SIZE]))\n",
    "env_police = np.matrix(np.zeros([MATRIX_SIZE, MATRIX_SIZE]))\n",
    "env_drugs = np.matrix(np.zeros([MATRIX_SIZE, MATRIX_SIZE]))\n",
    "initial_state = 1\n",
    "  \n",
    "# Same as above\n",
    "def available_actions(state):\n",
    "    current_state_row = M[state, ]\n",
    "    av_action = np.where(current_state_row >= 0)[1]\n",
    "    return av_action\n",
    "  \n",
    "# Same as above\n",
    "def sample_next_action(available_actions_range):\n",
    "    next_action = int(np.random.choice(available_action, 1))\n",
    "    return next_action\n",
    "  \n",
    "# Exploring the environment\n",
    "def collect_environmental_data(action):\n",
    "    found = []\n",
    "    if action in police:\n",
    "        found.append('p')\n",
    "        if action in drug_traces:\n",
    "            found.append('d')\n",
    "            return (found) \n",
    "          \n",
    "available_action = available_actions(initial_state)\n",
    "action = sample_next_action(available_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb9762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(current_state, action, gamma):\n",
    "max_index = np.where(Q[action, ] == np.max(Q[action, ]))[1]\n",
    "if max_index.shape[0] > 1:\n",
    "    max_index = int(np.random.choice(max_index, size = 1))\n",
    "    else:\n",
    "        max_index = int(max_index)\n",
    "        max_value = Q[action, max_index]\n",
    "        Q[current_state, action] = M[current_state, action] + gamma * max_value\n",
    "        environment = collect_environmental_data(action)\n",
    "        if 'p' in environment:\n",
    "            env_police[current_state, action] += 1\n",
    "            if 'd' in environment:\n",
    "                env_drugs[current_state, action] += 1\n",
    "                if (np.max(Q) > 0):\n",
    "                    return(np.sum(Q / np.max(Q)*100))\n",
    "                else:\n",
    "                    return (0)\n",
    "# Same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d4815",
   "metadata": {},
   "outputs": [],
   "source": [
    "update(initial_state, action, gamma)\n",
    "  \n",
    "def available_actions_with_env_help(state):\n",
    "    current_state_row = M[state, ]\n",
    "    av_action = np.where(current_state_row >= 0)[1]\n",
    "  \n",
    "    # if there are multiple routes, dis-favor anything negative\n",
    "    env_pos_row = env_matrix_snap[state, av_action]\n",
    "    if (np.sum(env_pos_row < 0)):\n",
    "        # can we remove the negative directions from av_act?\n",
    "        temp_av_action = av_action[np.array(env_pos_row)[0]>= 0]\n",
    "        if len(temp_av_action) > 0:\n",
    "            av_action = temp_av_action\n",
    "            return av_action\n",
    "        # Determines the available actions according to the environment\n",
    "        scores = []\n",
    "        for i in range(1000):\n",
    "            current_state = np.random.randint(0, int(Q.shape[0]))\n",
    "            available_action = available_actions(current_state)\n",
    "            action = sample_next_action(available_action)\n",
    "            score = update(current_state, action, gamma) \n",
    "            # print environmental matrices\n",
    "            print('Police Found')\n",
    "            print(env_police)\n",
    "            print('')\n",
    "            print('Drug traces Found')\n",
    "            print(env_drugs)\n",
    "            scores = []\n",
    "            for i in range(1000):\n",
    "                current_state = np.random.randint(0, int(Q.shape[0]))\n",
    "                available_action = available_actions_with_env_help(current_state)\n",
    "                action = sample_next_action(available_action)\n",
    "                score = update(current_state, action, gamma)\n",
    "                scores.append(score)  \n",
    "                pl.plot(scores)\n",
    "                pl.xlabel('Number of iterations')\n",
    "                pl.ylabel('Reward gained')\n",
    "                pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a3d62b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
